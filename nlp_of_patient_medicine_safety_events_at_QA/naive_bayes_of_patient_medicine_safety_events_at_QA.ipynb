{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with loading all necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "('01000', \"[01000] [unixODBC][Driver Manager]Can't open lib 'SQL Server' : file not found (0) (SQLDriverConnect)\")",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d4d5af2c16dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m sql_conn = pyodbc.connect('DRIVER={SQL Server};'\n\u001b[0m\u001b[1;32m      2\u001b[0m                             \u001b[0;34m'SERVER=L_AAGDATIX;'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                             \u001b[0;34m'DATABASE=DatixCRM;'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                             'Trusted_Connection=yes') \n\u001b[1;32m      5\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"set transaction isolation level read uncommitted select inc_organisation,inc_locactual,inc_unit,inc_specialty,inc_loctype,inc_result,inc_severity,show_other_contacts,show_employee,show_witness,show_document,inc_reportedby,inc_notes from DatixCRM.dbo.incidents_main where inc_type='PAT' and inc_category='MEDIC'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mError\u001b[0m: ('01000', \"[01000] [unixODBC][Driver Manager]Can't open lib 'SQL Server' : file not found (0) (SQLDriverConnect)\")"
     ]
    }
   ],
   "source": [
    "sql_conn = pyodbc.connect('DRIVER={SQL Server};'\n",
    "                            'SERVER=L_AAGDATIX;'\n",
    "                            'DATABASE=DatixCRM;'\n",
    "                            'Trusted_Connection=yes') \n",
    "query = \"set transaction isolation level read uncommitted select inc_organisation,inc_locactual,inc_unit,inc_specialty,inc_loctype,inc_result,inc_severity,show_other_contacts,show_employee,show_witness,show_document,inc_reportedby,inc_notes from DatixCRM.dbo.incidents_main where inc_type='PAT' and inc_category='MEDIC'\"\n",
    "df = pd.read_sql(query, sql_conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['division'] = df['inc_unit'].str[:3]\n",
    "df['care group'] = df['inc_unit'].str[3:6]\n",
    "df = df.drop('inc_unit',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-67a315271f1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcategory_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcategory_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inc_notes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0maccuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcategory_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "category_columns = list(df.columns.values)\n",
    "category_columns.remove('inc_notes')\n",
    "count_accuracies = []\n",
    "tfidf_accuracies = []\n",
    "for column in category_columns:\n",
    "    df = df.dropna(subset=[column])\n",
    "    y = df[column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                    df['inc_notes'], y,\n",
    "                                    test_size=0.33,\n",
    "                                    random_state=53)\n",
    "    count_vectorizer = CountVectorizer(stop_words='english')\n",
    "    count_train = count_vectorizer.fit_transform(X_train.values)\n",
    "    count_test = count_vectorizer.transform(X_test.values)\n",
    "    # Print the first 10 features of the count_vectorizer\n",
    "    #print(count_vectorizer.get_feature_names()[:10])\n",
    "\n",
    "\n",
    "    # Initialize a TfidfVectorizer object: tfidf_vectorizer\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\",max_df=0.7)\n",
    "\n",
    "    # Transform the training data: tfidf_train \n",
    "    tfidf_train = tfidf_vectorizer.fit_transform(X_train.values)\n",
    "\n",
    "    # Transform the test data: tfidf_test \n",
    "    tfidf_test = tfidf_vectorizer.transform(X_test.values)\n",
    "\n",
    "    # Print the first 10 features\n",
    "    #print(tfidf_vectorizer.get_feature_names()[:10])\n",
    "\n",
    "    # Print the first 5 vectors of the tfidf training data\n",
    "    #print(tfidf_train.A[:5])\n",
    "\n",
    "\n",
    "    # Create the CountVectorizer DataFrame: count_df\n",
    "    #count_df = pd.DataFrame(count_train.A, columns=count_vectorizer.get_feature_names())\n",
    "\n",
    "    # Create the TfidfVectorizer DataFrame: tfidf_df\n",
    "    #tfidf_df = pd.DataFrame(tfidf_train.A, columns=tfidf_vectorizer.get_feature_names())\n",
    "\n",
    "    # Print the head of count_df\n",
    "    #print(count_df.head())\n",
    "\n",
    "    # Print the head of tfidf_df\n",
    "    #print(tfidf_df.head())\n",
    "\n",
    "    # Calculate the difference in columns: difference\n",
    "    #difference = set(count_df.columns) - set(tfidf_df.columns)\n",
    "    #print(difference)\n",
    "\n",
    "    # Check whether the DataFrames are equal\n",
    "    #print(count_df.equals(tfidf_df))\n",
    "\n",
    "\n",
    "    count_nb_classifier = MultinomialNB()\n",
    "    count_nb_classifier.fit(count_train, y_train)\n",
    "    count_pred = nb_classifier.predict(count_test)\n",
    "    count_accuracies.append(100*metrics.accuracy_score(y_test,count_pred))\n",
    "    \n",
    "    tfidf_nb_classifier = MultinomialNB()\n",
    "    tfidf_nb_classifier.fit(tfidf_train, y_train)\n",
    "    tfidf_pred = nb_classifier.predict(tfidf_test)\n",
    "    tfidf_accuracies.append(100*metrics.accuracy_score(y_test,tfidf_pred))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-220e83754bd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfrom50\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maccuracies\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mn_category_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'green'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfrom50\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'red'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcategory_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inc_organisation'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'site'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcategory_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcategory_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inc_locactual'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ward/dept/unit'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcategory_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracies' is not defined"
     ]
    }
   ],
   "source": [
    "count_from50 = [int(round(accuracy/2)) for accuracy in count_accuracies]\n",
    "n_category_columns = len(category_columns)\n",
    "colors = [['green' if count_from50[j]>i else 'red' for j in range(n_category_columns)] for i in range(50)]\n",
    "category_columns = [column.replace('inc_organisation','site') for column in category_columns]\n",
    "category_columns = [column.replace('inc_locactual','ward/dept/unit') for column in category_columns]\n",
    "category_columns = [column.replace('inc_unit','division & care group') for column in category_columns]\n",
    "category_columns = [column.replace('inc_specialty','specialty') for column in category_columns]\n",
    "category_columns = [column.replace('inc_loctype','location type') for column in category_columns]\n",
    "category_columns = [column.replace('inc_result','result') for column in category_columns]\n",
    "category_columns = [column.replace('inc_severity','severity') for column in category_columns]\n",
    "category_columns = [column.replace('inc_reportedby','reported by') for column in category_columns]\n",
    "category_columns = [column.replace('show_other_contacts','other patients involved?') for column in category_columns]\n",
    "category_columns = [column.replace('show_employee','other employees involved?') for column in category_columns]\n",
    "category_columns = [column.replace('show_witness','any witnesses?') for column in category_columns]\n",
    "category_columns = [column.replace('show_document','any documents attached?') for column in category_columns]\n",
    "for i in range(50):\n",
    "    plt.scatter(x=np.ones(len(category_columns))*(i+1),y=category_columns,color=colors[i])\n",
    "plt.xlim((0,51));\n",
    "fig1 = plt.figure(1)\n",
    "fig1.text(0, 0.95, \"Correct\", ha=\"center\", va=\"bottom\", size=\"large\", color=\"green\");\n",
    "fig1.text(0.06, 0.95, \"/\", ha=\"center\", va=\"bottom\", size=\"large\");\n",
    "fig1.text(0.13,0.95,\"Incorrect\", ha=\"center\", va=\"bottom\", size=\"large\", color=\"red\");\n",
    "fig1.text(0.19, 0.95, \" prediction from freetext entry for medicine patient safety events\", va=\"bottom\", size=\"large\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_from50 = [int(round(accuracy/2)) for accuracy in tfidf_accuracies]\n",
    "colors = [['green' if tfidf_from50[j]>i else 'red' for j in range(n_category_columns)] for i in range(50)]\n",
    "for i in range(50):\n",
    "    plt.scatter(x=np.ones(len(category_columns))*(i+1),y=category_columns,color=colors[i])\n",
    "plt.xlim((0,51));\n",
    "fig1 = plt.figure(1)\n",
    "fig1.text(0, 0.95, \"Correct\", ha=\"center\", va=\"bottom\", size=\"large\", color=\"green\");\n",
    "fig1.text(0.06, 0.95, \"/\", ha=\"center\", va=\"bottom\", size=\"large\");\n",
    "fig1.text(0.13,0.95,\"Incorrect\", ha=\"center\", va=\"bottom\", size=\"large\", color=\"red\");\n",
    "fig1.text(0.19, 0.95, \" prediction from freetext entry for medicine patient safety events\", va=\"bottom\", size=\"large\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'category_columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-beb7b5414046>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcategory_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'category_columns' is not defined"
     ]
    }
   ],
   "source": [
    "for column in category_columns:\n",
    "    classes = [str(i) for i in df[column].value_counts().index]\n",
    "    cm = metrics.confusion_matrix(y_test, count_pred, labels=classes)\n",
    "    \n",
    "    # https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, cmap=plt.cm.Blues)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title='True vs Predicted label from freetext of medicine patient safety events',\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in category_columns:\n",
    "    classes = [str(i) for i in df[column].value_counts().index]\n",
    "    cm = metrics.confusion_matrix(y_test, tfidf_pred, labels=classes)\n",
    "    \n",
    "    # https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, cmap=plt.cm.Blues)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title='True vs Predicted label from freetext of medicine patient safety events',\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of alphas: alphas\n",
    "alphas = np.arange(0,1,0.1)\n",
    "\n",
    "# Define train_and_predict()\n",
    "def count_train_and_predict(column,alpha):\n",
    "    df = df.dropna(subset=[column])\n",
    "    y = df[column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                    df['inc_notes'], y,\n",
    "                                    test_size=0.33,\n",
    "                                    random_state=53)\n",
    "\n",
    "    # Initialize a CountVectorizer object: count_vectorizer\n",
    "    count_vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "    # Transform the training data: count_train \n",
    "    count_train = count_vectorizer.fit_transform(X_train.values)\n",
    "\n",
    "    # Transform the test data: count_test \n",
    "    count_test = count_vectorizer.transform(X_test.values)\n",
    "    \n",
    "    # Instantiate the classifier: nb_classifier\n",
    "    nb_classifier = MultinomialNB(alpha=alpha)\n",
    "    # Fit to the training data\n",
    "    nb_classifier.fit(count_train, y_train)\n",
    "    # Predict the labels: pred\n",
    "    pred = nb_classifier.predict(count_test)\n",
    "    # Compute accuracy: score\n",
    "    score = metrics.accuracy_score(y_test,pred)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the alphas and print the corresponding score\n",
    "for alpha in alphas:\n",
    "    print('Alpha: ', alpha)\n",
    "    for column in category_columns:\n",
    "        print('Column: ', column, ' Score: ', count_train_and_predict(column,alpha))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of alphas: alphas\n",
    "alphas = np.arange(0,1,0.1)\n",
    "\n",
    "# Define train_and_predict()\n",
    "def tfidf_train_and_predict(column,alpha):\n",
    "    df = df.dropna(subset=[column])\n",
    "    y = df[column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                    df['inc_notes'], y,\n",
    "                                    test_size=0.33,\n",
    "                                    random_state=53)\n",
    "\n",
    "    # Initialize a TfidfVectorizer object: tfidf_vectorizer\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\",max_df=0.7)\n",
    "\n",
    "    # Transform the training data: tfidf_train \n",
    "    tfidf_train = tfidf_vectorizer.fit_transform(X_train.values)\n",
    "\n",
    "    # Transform the test data: tfidf_test \n",
    "    tfidf_test = tfidf_vectorizer.transform(X_test.values)\n",
    "    \n",
    "    # Instantiate the classifier: nb_classifier\n",
    "    nb_classifier = MultinomialNB(alpha=alpha)\n",
    "    # Fit to the training data\n",
    "    nb_classifier.fit(tfidf_train, y_train)\n",
    "    # Predict the labels: pred\n",
    "    pred = nb_classifier.predict(tfidf_test)\n",
    "    # Compute accuracy: score\n",
    "    score = metrics.accuracy_score(y_test,pred)\n",
    "    \n",
    "    # Get the class labels: class_labels\n",
    "    class_labels = nb_classifier.classes_\n",
    "\n",
    "    # Extract the features: feature_names\n",
    "    feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "    # Zip the feature names together with the coefficient array and sort by weights: feat_with_weights\n",
    "    feat_with_weights = sorted(zip(nb_classifier.coef_[0], feature_names))\n",
    "\n",
    "    # Print the first class label and the bottom 20  feat_with_weights entries\n",
    "    for i in range(len(class_labels)):\n",
    "        print(class_labels[i], feat_with_weights[-20:])\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the alphas and print the corresponding score\n",
    "for alpha in alphas:\n",
    "    print('Alpha: ', alpha)\n",
    "    for column in category_columns:\n",
    "        print('Column: ', column, ' Score: ', tfidf_train_and_predict(column,alpha))\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
